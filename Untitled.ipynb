{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "988330df-4794-45c5-b358-086ace9c1ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('pandasToSparkDF').getOrCreate()\n",
    "\n",
    "from pyspark.sql.functions import mean, col, split, regexp_extract, when, lit\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, QuantileDiscretizer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fe47a13-685c-479f-9109-764af25407d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111\n"
     ]
    }
   ],
   "source": [
    "print(111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54681b78-7808-4881-a415-21e283278d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7075c844-5e43-4940-b899-64364a09b0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import pandas_udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8891e045-11b6-44c8-bef3-689fcfff8cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "@pandas_udf(IntegerType())\n",
    "def slen(s: pd.Series) -> pd.Series:\n",
    "    return s.str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19012ef4-585d-4001-9da4-0e021adf9af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "@pandas_udf(IntegerType())\n",
    "def slen(s: pd.Series) -> pd.Series:\n",
    "    return s.str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f678ef09-c2f4-45f9-96e1-7e3a2cf1d1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pandas_udf(\"string\")\n",
    "def to_upper(s: pd.Series) -> pd.Series:\n",
    "    return s.str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd71a136-750f-442d-96d4-40ed705e2bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|to_upper(name)|\n",
      "+--------------+\n",
      "|      JOHN DOE|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame([(\"John Doe\",)], (\"name\",))\n",
    "df.select(to_upper(\"name\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ef02fa-b3e6-4432-872a-0fb44e750f95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b7a2ead-b669-41a4-9f0e-e84d66640b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|       show|\n",
      "+-----------+\n",
      "|{John, Doe}|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@pandas_udf(\"first string, last string\")\n",
    "def split_expand(s: pd.Series) -> pd.DataFrame:\n",
    "    return s.str.split(expand=True)\n",
    "df = spark.createDataFrame([(\"John Doe\",)], (\"name\",))\n",
    "df.select(split_expand(\"name\").alias(\"show\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fcde80a7-2938-4260-bbea-db035a2ae030",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StructType, StructField, FloatType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"foo\", FloatType(), False),\n",
    "    StructField(\"bar\", FloatType(), False)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "673dec32-9aca-41e4-a7d0-d737ac295f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- foobar: struct (nullable = true)\n",
      " |    |-- foo: float (nullable = false)\n",
      " |    |-- bar: float (nullable = false)\n",
      "\n",
      "+----------+\n",
      "|    foobar|\n",
      "+----------+\n",
      "|{1.0, 0.0}|\n",
      "|{1.5, 1.0}|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def udf_test(n):\n",
    "    return (n / 2, n % 2) if n and n != 0.0 else (float('nan'), float('nan'))\n",
    "\n",
    "test_udf = udf(udf_test, schema)\n",
    "df = spark.createDataFrame(([(1, 2.0), (2, 3.0)]),(\"x\",\"y\"))\n",
    "\n",
    "foobars = df.select(test_udf(\"y\").alias(\"foobar\"))\n",
    "foobars.printSchema()\n",
    "foobars.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e132fa9-31cf-40d4-a89d-3d5b0dfb6f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- aaa: struct (nullable = true)\n",
      " |    |-- foo: float (nullable = false)\n",
      " |    |-- bar: float (nullable = false)\n",
      "\n",
      "+-----------+\n",
      "|        aaa|\n",
      "+-----------+\n",
      "|{24.0, 3.0}|\n",
      "|{25.0, 4.0}|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "d_struct = StructType([\n",
    "    StructField(\"foo\", FloatType(), False),\n",
    "    StructField(\"bar\", FloatType(), False)\n",
    "])\n",
    "\n",
    "def dataframe_udf(udf_test_dataframe,\n",
    "    def udf_test_dataframe(n)-> pd.DataFrame:\n",
    "        print(n)\n",
    "        print(type(n))\n",
    "        print(111111)\n",
    "        return n+22,n+1\n",
    "    return\n",
    "\n",
    "#dataframe_udf = udf(udf_test_dataframe, schema)\n",
    "df = spark.createDataFrame(([(1, 2.0), (2, 3.0)]),(\"x\",\"y\"))\n",
    "\n",
    "foobars = df.select(dataframe_udf(\"y\").alias(\"aaa\"))\n",
    "foobars.printSchema()\n",
    "foobars.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9124b409-baa5-4471-a471-e0d376ec80c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
