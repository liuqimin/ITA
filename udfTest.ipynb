{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fe47a13-685c-479f-9109-764af25407d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111\n"
     ]
    }
   ],
   "source": [
    "print(111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "988330df-4794-45c5-b358-086ace9c1ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('pandasToSparkDF').getOrCreate()\n",
    "\n",
    "from pyspark.sql.functions import mean, col, split, regexp_extract, when, lit\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, QuantileDiscretizer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54681b78-7808-4881-a415-21e283278d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7075c844-5e43-4940-b899-64364a09b0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import pandas_udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8891e045-11b6-44c8-bef3-689fcfff8cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "@pandas_udf(IntegerType())\n",
    "def slen(s: pd.Series) -> pd.Series:\n",
    "    return s.str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19012ef4-585d-4001-9da4-0e021adf9af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "@pandas_udf(IntegerType())\n",
    "def slen(s: pd.Series) -> pd.Series:\n",
    "    return s.str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f678ef09-c2f4-45f9-96e1-7e3a2cf1d1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pandas_udf(\"string\")\n",
    "def to_upper(s: pd.Series) -> pd.Series:\n",
    "    return s.str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd71a136-750f-442d-96d4-40ed705e2bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|to_upper(name)|\n",
      "+--------------+\n",
      "|      JOHN DOE|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame([(\"John Doe\",)], (\"name\",))\n",
    "df.select(to_upper(\"name\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ef02fa-b3e6-4432-872a-0fb44e750f95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b7a2ead-b669-41a4-9f0e-e84d66640b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|       show|\n",
      "+-----------+\n",
      "|{John, Doe}|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@pandas_udf(\"first string, last string\")\n",
    "def split_expand(s: pd.Series) -> pd.DataFrame:\n",
    "    return s.str.split(expand=True)\n",
    "df = spark.createDataFrame([(\"John Doe\",)], (\"name\",))\n",
    "df.select(split_expand(\"name\").alias(\"show\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fcde80a7-2938-4260-bbea-db035a2ae030",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StructType, StructField, FloatType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"foo\", FloatType(), False),\n",
    "    StructField(\"bar\", FloatType(), False)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "673dec32-9aca-41e4-a7d0-d737ac295f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- foobar: struct (nullable = true)\n",
      " |    |-- foo: float (nullable = false)\n",
      " |    |-- bar: float (nullable = false)\n",
      "\n",
      "+----------+\n",
      "|    foobar|\n",
      "+----------+\n",
      "|{1.0, 0.0}|\n",
      "|{1.5, 1.0}|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#返回多重树值\n",
    "def udf_test(n):\n",
    "    return (n / 2, n % 2) if n and n != 0.0 else (float('nan'), float('nan'))\n",
    "\n",
    "test_udf = udf(udf_test, schema)\n",
    "df = spark.createDataFrame(([(1, 2.0), (2, 3.0)]),(\"x\",\"y\"))\n",
    "\n",
    "foobars = df.select(test_udf(\"y\").alias(\"foobar\"))\n",
    "foobars.printSchema()\n",
    "foobars.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1e132fa9-31cf-40d4-a89d-3d5b0dfb6f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- aaa: struct (nullable = true)\n",
      " |    |-- foo: float (nullable = false)\n",
      " |    |-- bar: float (nullable = false)\n",
      "\n",
      "+-----------+\n",
      "|        aaa|\n",
      "+-----------+\n",
      "|{24.0, 3.0}|\n",
      "|{25.0, 4.0}|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#多重返回dataframe\n",
    "d_struct = StructType([\n",
    "    StructField(\"foo\", FloatType(), False),\n",
    "    StructField(\"bar\", FloatType(), False)\n",
    "])\n",
    "\n",
    "\n",
    "@udf(schema)\n",
    "def udf_test_dataframe(n)-> pd.DataFrame:\n",
    "    print(n)\n",
    "    print(type(n))\n",
    "    print(111111)\n",
    "    return n+22,n+1\n",
    "\n",
    "#dataframe_udf = udf(udf_test_dataframe, schema)\n",
    "df = spark.createDataFrame(([(1, 2.0), (2, 3.0)]),(\"x\",\"y\"))\n",
    "\n",
    "foobars = df.select(udf_test_dataframe(\"y\").alias(\"aaa\"))\n",
    "foobars.printSchema()\n",
    "foobars.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9124b409-baa5-4471-a471-e0d376ec80c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- footbar: struct (nullable = true)\n",
      " |    |-- foo: float (nullable = false)\n",
      " |    |-- bar: float (nullable = false)\n",
      "\n",
      "+----+---+\n",
      "| foo|bar|\n",
      "+----+---+\n",
      "|24.0|3.0|\n",
      "|25.0|4.0|\n",
      "+----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#多重返回dataframe\n",
    "d_struct = StructType([\n",
    "    StructField(\"foo\", FloatType(), False),\n",
    "    StructField(\"bar\", FloatType(), False)\n",
    "])\n",
    "\n",
    "\n",
    "@udf(schema)\n",
    "def udf_test_dataframe(n)-> pd.DataFrame:\n",
    "    print(n)\n",
    "    print(type(n))\n",
    "    print(111111)\n",
    "    return n+22,n+1\n",
    "\n",
    "#dataframe_udf = udf(udf_test_dataframe, schema)\n",
    "df = spark.createDataFrame(([(1, 2.0), (2, 3.0)]),(\"x\",\"y\"))\n",
    "\n",
    "#create virtual table. talbe columns is footbar.foo  And footbar.bar\n",
    "foobars = df.select(udf_test_dataframe(\"y\").alias(\"footbar\"))\n",
    "#foobars=df.withColumn('udf_results',udf_test_dataframe)  \n",
    "foobars.printSchema()\n",
    "foobars.select(\"footbar.foo\",\"footbar.bar\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d67e1cd0-bbeb-4e76-8c89-ed75ec121a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+\n",
      "| ID|  A|  B|\n",
      "+---+---+---+\n",
      "|101|  1| 16|\n",
      "+---+---+---+\n",
      "\n",
      "+---+---+---+------+\n",
      "| ID|  A|  B|Result|\n",
      "+---+---+---+------+\n",
      "|101|  1| 16|    17|\n",
      "+---+---+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##多个参数\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "def sum(x, y):\n",
    "    return x + y\n",
    "\n",
    "sum_cols = udf(sum, IntegerType())\n",
    "\n",
    "a=spark.createDataFrame([(101, 1, 16)], ['ID', 'A', 'B'])\n",
    "a.show()\n",
    "a.withColumn('Result', sum_cols('A', 'B')).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3935fe6d-2e31-4517-aed3-c7fb41f81103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- footbar: struct (nullable = true)\n",
      " |    |-- foo: float (nullable = false)\n",
      " |    |-- bar: float (nullable = false)\n",
      "\n",
      "+----+---+\n",
      "| foo|bar|\n",
      "+----+---+\n",
      "|24.0|3.0|\n",
      "|25.0|4.0|\n",
      "+----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#多个参数 多重返回dataframe\n",
    "d_struct = StructType([\n",
    "    StructField(\"foo\", FloatType(), False),\n",
    "    StructField(\"bar\", FloatType(), False)\n",
    "])\n",
    "\n",
    "\n",
    "@udf(schema)\n",
    "def udf_test_dataframe(n,a)-> pd.DataFrame:\n",
    "    print(n)\n",
    "    print(type(n))\n",
    "    print(111111)\n",
    "    return n+22,n+1\n",
    "\n",
    "#dataframe_udf = udf(udf_test_dataframe, schema)\n",
    "df = spark.createDataFrame(([(1, 2.0), (2, 3.0)]),(\"x\",\"y\"))\n",
    "\n",
    "#create virtual table. talbe columns is footbar.foo  And footbar.bar\n",
    "foobars = df.select(udf_test_dataframe(\"y\",\"x\").alias(\"footbar\"))\n",
    "#foobars=df.withColumn('udf_results',udf_test_dataframe)  \n",
    "foobars.printSchema()\n",
    "foobars.select(\"footbar.foo\",\"footbar.bar\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8bf6c8-781e-44a0-a816-6904e6dc5cf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
